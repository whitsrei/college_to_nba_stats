{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data sets that we have come with a lot of stats about the players. In this step we are going through and removing players that didn't come from the NCAA (Europe) and trimming down the attributes to the things that we believe are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def get_table(filename):\n",
    "    table = []\n",
    "    infile = open(filename)\n",
    "    lines = infile.readlines()\n",
    "    \n",
    "    i = 0\n",
    "    for line in lines:\n",
    "        add_it = True\n",
    "        line = line.strip()\n",
    "        line = line.strip('\\n')\n",
    "        values = line.split(\",\")\n",
    "       \n",
    "        #this is only grabbing columns that are completely filled in\n",
    "        if len(values) > 27:        \n",
    "            for val in values:\n",
    "                #Get rid of columns with NA in them\n",
    "                if val == 'NA':\n",
    "                    add_it = False\n",
    "            if add_it:     \n",
    "                #player - 6\n",
    "                #pick - 4\n",
    "                #MP - 31\n",
    "                #FG - 32\n",
    "                #FG% - 34\n",
    "                #3p - 38\n",
    "                #3pt% - 40\n",
    "                #FT - 41\n",
    "                #PTS - 52\n",
    "                #SOS - 54\n",
    "                #NBA PTS - 15\n",
    "                \n",
    "                to_add = []\n",
    "                to_add.append(values[6])\n",
    "                to_add.append(values[4])\n",
    "                to_add.append(values[31])\n",
    "                to_add.append(values[32])\n",
    "                to_add.append(values[34])\n",
    "                to_add.append(values[38])\n",
    "                if values[40] == '':\n",
    "                    to_add.append(0.0)\n",
    "                else:\n",
    "                    to_add.append(values[40])\n",
    "                to_add.append(values[41])\n",
    "                to_add.append(values[52])\n",
    "                to_add.append(values[54])\n",
    "                to_add.append(values[15])\n",
    "                convert_to_numeric(to_add)\n",
    "                table.append(to_add)\n",
    "    infile.close()\n",
    "    return table\n",
    "\n",
    "\n",
    "def convert_to_numeric(values):\n",
    "    '''\n",
    "    converts values read from a file into correct types\n",
    "    '''\n",
    "    for i in range(len(values)):\n",
    "        try:\n",
    "            #converts numerical values from strings to floats\n",
    "            numeric_val = float(values[i])\n",
    "            values[i] = numeric_val\n",
    "        except ValueError:\n",
    "            values[i] = values[i].strip('\\\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic KNN_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_column and compute_distances\n",
    "Here are 2 helper functions for the KNN algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column(table, column_index):\n",
    "    column = []\n",
    "    for row in table:\n",
    "        if row[column_index] != 'NA':\n",
    "            column.append(row[column_index])\n",
    "    return column\n",
    "\n",
    "def compute_distances(v1,v2,table):\n",
    "    assert(len(v1) == len(v2))\n",
    "\n",
    "    dist = 0\n",
    "    for i in range(1, len(v1)-1):\n",
    "        Min = min(get_column(table, i))\n",
    "        Max = max(get_column(table, i))\n",
    "        v1_N = normalize(v1[i], Min, Max)\n",
    "        v2_N = normalize(v2[i], Min, Max)\n",
    "    \n",
    "        dist += (v1_N- v2_N) ** 2\n",
    "    return math.sqrt(dist)\n",
    "\n",
    "def normalize(x, Min, Max):\n",
    "    '''\n",
    "    normalizes data before distance calculations\n",
    "    '''\n",
    "    normalized = ((x - Min) / (Max - Min)) * 1.0\n",
    "    return normalized\n",
    "\n",
    "def k_fold(table):\n",
    "    randomized = table[:]\n",
    "    n = len(randomized)\n",
    "\n",
    "    for i in range(n):\n",
    "        rand_index = random.randrange(0,n)\n",
    "        randomized[i], randomized[rand_index] = randomized[rand_index], randomized[i]\n",
    "\n",
    "\n",
    "    folds = [[] for i in range(10)]\n",
    "    x = 0\n",
    "    for i in range(len(randomized)):\n",
    "        if x > 9:\n",
    "            x = 0\n",
    "        folds[x].append(randomized[i])\n",
    "        x += 1\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the knn guess function where i take in the training set and the test set and find its nearest neighbors, compute the avg of the nearest neighbors and return the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_guess(train_set, test_set, k_val):\n",
    "    '''\n",
    "    classifier using knn given a test set, train set and k value\n",
    "    '''\n",
    "    \n",
    "    init_len = len(train_set)\n",
    "    init_row_len = len(train_set[0])\n",
    "    \n",
    "    right = 0\n",
    "    wrong = 0\n",
    "\n",
    "    for row in train_set:\n",
    "        row.append(compute_distances(row, test_set, train_set))  \n",
    "\n",
    "    k = k_val\n",
    "    \n",
    "    length_of_rows = len(train_set[0])\n",
    "    train_set.sort(key=operator.itemgetter(length_of_rows-1))\n",
    "\n",
    "    top_k = train_set[:k]\n",
    "\n",
    "    # calculate the averages from the nearest neighbors\n",
    "    sum_ppg = 0\n",
    "    for player in top_k:\n",
    "        sum_ppg += player[init_row_len-1]\n",
    "    avg_ppg = sum_ppg/len(top_k)\n",
    "\n",
    "    for row in train_set:\n",
    "        row.pop()\n",
    "    \n",
    "    return avg_ppg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i created a k-fold that just works for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a the knn function that runs over the adds them to a list to be computed at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnPrediction(table, headers, avg_error, median_error):    \n",
    "    folds = k_fold(table)\n",
    "    differences = []\n",
    "    for i in range(len(folds)):\n",
    "        train_set = []\n",
    "\n",
    "        for x in folds:\n",
    "            if x != folds[i]:\n",
    "                for item in x:\n",
    "                    train_set.append(item)\n",
    "        for j in folds[i]:\n",
    "            my_guess = knn_guess(train_set, j, 10)\n",
    "            #uncomment below to see the specific predicted points per game vs actual NBA points\n",
    "            #print (\"NBA PPG: \" + str(j[-1]))\n",
    "            #print (\"predicted PPG: \" + str(my_guess))\n",
    "            diff = j[-1] - my_guess\n",
    "            differences.append(abs(diff))\n",
    "\n",
    "    avg_error.append(np.mean(differences))\n",
    "    median_error.append(np.median(differences))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function outputs a table of correelation coefficents for all the attributes we used for our kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SELF MADE KNN----------\n",
      "Average error : 4.12\n",
      "Median error : 3.64\n"
     ]
    }
   ],
   "source": [
    "#fxn that calls KNN-self-done\n",
    "\n",
    "start_table = get_table('datasets/firstRoundPicks_withCollegeStats.csv')\n",
    "headers = start_table[0]\n",
    "table = start_table[1:]\n",
    "\n",
    "ensemble_size = 6\n",
    "\n",
    "list_of_ind = [i for i in range(1,10)]\n",
    "\n",
    "avg_error = []\n",
    "median_error = []\n",
    "\n",
    "for _ in range(ensemble_size):\n",
    "    X = []\n",
    "    attributes = list_of_ind\n",
    "    random.shuffle(attributes)\n",
    "    attributes = attributes[:4]\n",
    "\n",
    "    for row in table:\n",
    "        inter = []\n",
    "        for i in attributes:\n",
    "            inter.append(row[i])\n",
    "        inter.append(row[-1])\n",
    "        X.append(inter)\n",
    "    \n",
    "    knnPrediction(X, headers, avg_error, median_error)\n",
    "\n",
    "total_avg_error = sum(avg_error) / len(avg_error)\n",
    "total_median_error = sum(median_error) / len(median_error)\n",
    "\n",
    "print(\"---------SELF MADE KNN----------\")\n",
    "print(\"Average error : %.2f\" % total_avg_error)\n",
    "print(\"Median error : %.2f\" % total_median_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below does the same as above but using the scikit-learn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Total points off for sci-kit learn: 3.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "list_of_ind = [i for i in range(1,10)]\n",
    "player_pred = [0 for _ in range(len(table))]\n",
    "Y = [row[10] for row in table]\n",
    "\n",
    "for _ in range(ensemble_size):\n",
    "    X = []\n",
    "    #randomly generate 4 numbers to be included\n",
    "    attributes = list_of_ind\n",
    "    random.shuffle(attributes)\n",
    "    attributes = attributes[:4]\n",
    "\n",
    "    for row in table:\n",
    "        inter = []\n",
    "        for i in attributes:\n",
    "            inter.append(row[i])\n",
    "        X.append(inter)\n",
    "\n",
    "    n = KNeighborsRegressor(n_neighbors=5)\n",
    "    n.fit(X,Y)\n",
    "\n",
    "    for i, player in enumerate(table):\n",
    "        rows_to_analyze = [player[a] for a in attributes]\n",
    "        player_pred[i] += (n.predict([rows_to_analyze]))[0]\n",
    "\n",
    "final_pred = [pred / ensemble_size for pred in player_pred]\n",
    "\n",
    "total_error = 0\n",
    "\n",
    "for i,player in enumerate(table):\n",
    "    #uncomment if you want to see each player\n",
    "    #print(\"Player -> \" , player[0])\n",
    "    #print(\"Guessed PPG \" , final_pred[i])\n",
    "    #print(\"Actual PPG \" , player[10])\n",
    "    #print()\n",
    "    total_error += abs(final_pred[i] - player[10])\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "print(\"Total points off for sci-kit learn: %.2f\" % (total_error / len(table)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function that computes the correlation coefficient for each attribute, to give a sense of our attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pk correlation coefficent = -0.5273993822093086\n",
      "MP correlation coefficent = 0.21762848137756619\n",
      "FG correlation coefficent = 0.36933962519403424\n",
      "FG% correlation coefficent = -0.1449147250609018\n",
      "3P correlation coefficent = 0.16441215828431333\n",
      "3P% correlation coefficent = -0.046193036818175305\n",
      "FT correlation coefficent = 0.5101851304616711\n",
      "PTS correlation coefficent = 0.44179743881307093\n",
      "SOS correlation coefficent = 0.1796059783207265\n"
     ]
    }
   ],
   "source": [
    "def find_stat_correlation_to_NBA_PTS(table, headers):\n",
    "    NBA_PTS = get_column(table, 10)\n",
    "    for i in range(1, len(headers)-1):\n",
    "        cur_column = get_column(table, i)\n",
    "        vals = np.corrcoef(cur_column, NBA_PTS)\n",
    "        r = str(vals[0][-1])\n",
    "        print (headers[i] + \" correlation coefficent = \" + r)\n",
    "\n",
    "find_stat_correlation_to_NBA_PTS(table, headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
