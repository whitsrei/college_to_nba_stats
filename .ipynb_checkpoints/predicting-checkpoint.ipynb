{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data sets that we have come with a lot of stats about the players. In this step we are going through and removing players that didn't come from the NCAA (Europe) and trimming down the attributes to the things that we believe are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "def get_table(filename):\n",
    "    table = []\n",
    "    infile = open(filename)\n",
    "    lines = infile.readlines()\n",
    "    \n",
    "    i = 0\n",
    "    for line in lines:\n",
    "        add_it = True\n",
    "        line = line.strip()\n",
    "        line = line.strip('\\n')\n",
    "        values = line.split(\",\")\n",
    "       \n",
    "        #this is only grabbing columns that are completely filled in\n",
    "        if len(values) > 27:        \n",
    "            for val in values:\n",
    "                #Get rid of columns with NA in them\n",
    "                if val == 'NA':\n",
    "                    add_it = False\n",
    "            if add_it:     \n",
    "                #player - 6\n",
    "                #pick - 4\n",
    "                #MP - 31\n",
    "                #FG - 32\n",
    "                #FG% - 34\n",
    "                #3p - 38\n",
    "                #3pt% - 40\n",
    "                #FT - 41\n",
    "                #PTS - 52\n",
    "                #SOS - 54\n",
    "                #NBA PTS - 15\n",
    "                \n",
    "                to_add = []\n",
    "                to_add.append(values[6])\n",
    "                to_add.append(values[4])\n",
    "                to_add.append(values[31])\n",
    "                to_add.append(values[32])\n",
    "                to_add.append(values[34])\n",
    "                to_add.append(values[38])\n",
    "                if values[40] == '':\n",
    "                    to_add.append(0.0)\n",
    "                else:\n",
    "                    to_add.append(values[40])\n",
    "                to_add.append(values[41])\n",
    "                to_add.append(values[52])\n",
    "                to_add.append(values[54])\n",
    "                to_add.append(values[15])\n",
    "                utils.convert_to_numeric(to_add)\n",
    "                table.append(to_add)\n",
    "    infile.close()\n",
    "    return table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic KNN_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_column and compute_distances\n",
    "Here are 2 helper functions for the KNN algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the knn guess function where i take in the training set and the test set and find its nearest neighbors, compute the avg of the nearest neighbors and return the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_guess(train_set, test_set, k_val):\n",
    "    '''\n",
    "    classifier using knn given a test set, train set and k value\n",
    "    '''\n",
    "    \n",
    "    init_len = len(train_set)\n",
    "    init_row_len = len(train_set[0])\n",
    "    \n",
    "    right = 0\n",
    "    wrong = 0\n",
    "\n",
    "    for row in train_set:\n",
    "        row.append(utils.compute_distances(row, test_set, train_set))  \n",
    "\n",
    "    k = k_val\n",
    "    \n",
    "    length_of_rows = len(train_set[0])\n",
    "    train_set.sort(key=operator.itemgetter(length_of_rows-1))\n",
    "\n",
    "    top_k = train_set[:k]\n",
    "\n",
    "    # calculate the averages from the nearest neighbors\n",
    "    sum_ppg = 0\n",
    "    for player in top_k:\n",
    "        sum_ppg += player[init_row_len-1]\n",
    "    avg_ppg = sum_ppg/len(top_k)\n",
    "\n",
    "    for row in train_set:\n",
    "        row.pop()\n",
    "    \n",
    "    return avg_ppg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a the knn function that runs over the adds them to a list to be computed at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnPrediction(table, headers, avg_error, median_error):    \n",
    "    folds = utils.k_fold(table)\n",
    "    differences = []\n",
    "    for i in range(len(folds)):\n",
    "        train_set = []\n",
    "\n",
    "        for x in folds:\n",
    "            if x != folds[i]:\n",
    "                for item in x:\n",
    "                    train_set.append(item)\n",
    "        for j in folds[i]:\n",
    "            my_guess = knn_guess(train_set, j, 10)\n",
    "            #uncomment below to see the specific predicted points per game vs actual NBA points\n",
    "            #print (\"NBA PPG: \" + str(j[-1]))\n",
    "            #print (\"predicted PPG: \" + str(my_guess))\n",
    "            diff = j[-1] - my_guess\n",
    "            differences.append(abs(diff))\n",
    "\n",
    "    avg_error.append(np.mean(differences))\n",
    "    median_error.append(np.median(differences))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function outputs a table of correelation coefficents for all the attributes we used for our kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SELF MADE KNN----------\n",
      "Average error : 4.04\n",
      "Median error : 3.55\n"
     ]
    }
   ],
   "source": [
    "#fxn that calls KNN-self-done\n",
    "\n",
    "start_table = get_table('datasets/firstRoundPicks_withCollegeStats.csv')\n",
    "headers = start_table[0]\n",
    "table = start_table[1:]\n",
    "\n",
    "ensemble_size = 6\n",
    "\n",
    "list_of_ind = [i for i in range(1,10)]\n",
    "\n",
    "avg_error = []\n",
    "median_error = []\n",
    "\n",
    "for _ in range(ensemble_size):\n",
    "    X = []\n",
    "    attributes = list_of_ind\n",
    "    random.shuffle(attributes)\n",
    "    attributes = attributes[:4]\n",
    "\n",
    "    for row in table:\n",
    "        inter = []\n",
    "        for i in attributes:\n",
    "            inter.append(row[i])\n",
    "        inter.append(row[-1])\n",
    "        X.append(inter)\n",
    "    \n",
    "    knnPrediction(X, headers, avg_error, median_error)\n",
    "\n",
    "total_avg_error = sum(avg_error) / len(avg_error)\n",
    "total_median_error = sum(median_error) / len(median_error)\n",
    "\n",
    "print(\"---------SELF MADE KNN----------\")\n",
    "print(\"Average error : %.2f\" % total_avg_error)\n",
    "print(\"Median error : %.2f\" % total_median_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below does the same as above but using the scikit-learn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Total points off for sci-kit learn: 2.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "list_of_ind = [i for i in range(1,10)]\n",
    "player_pred = [0 for _ in range(len(table))]\n",
    "Y = [row[10] for row in table]\n",
    "\n",
    "for _ in range(ensemble_size):\n",
    "    X = []\n",
    "    #randomly generate 4 numbers to be included\n",
    "    attributes = list_of_ind\n",
    "    random.shuffle(attributes)\n",
    "    attributes = attributes[:4]\n",
    "\n",
    "    for row in table:\n",
    "        inter = []\n",
    "        for i in attributes:\n",
    "            inter.append(row[i])\n",
    "        X.append(inter)\n",
    "\n",
    "    n = KNeighborsRegressor(n_neighbors=5)\n",
    "    n.fit(X,Y)\n",
    "\n",
    "    for i, player in enumerate(table):\n",
    "        rows_to_analyze = [player[a] for a in attributes]\n",
    "        player_pred[i] += (n.predict([rows_to_analyze]))[0]\n",
    "\n",
    "final_pred = [pred / ensemble_size for pred in player_pred]\n",
    "\n",
    "total_error = 0\n",
    "\n",
    "for i,player in enumerate(table):\n",
    "    #uncomment if you want to see each player\n",
    "    #print(\"Player -> \" , player[0])\n",
    "    #print(\"Guessed PPG \" , final_pred[i])\n",
    "    #print(\"Actual PPG \" , player[10])\n",
    "    #print()\n",
    "    total_error += abs(final_pred[i] - player[10])\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "print(\"Total points off for sci-kit learn: %.2f\" % (total_error / len(table)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function that computes the correlation coefficient for each attribute, to give a sense of our attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pk correlation coefficent = -0.5273993822093086\n",
      "MP correlation coefficent = 0.21762848137756619\n",
      "FG correlation coefficent = 0.36933962519403424\n",
      "FG% correlation coefficent = -0.1449147250609018\n",
      "3P correlation coefficent = 0.16441215828431333\n",
      "3P% correlation coefficent = -0.046193036818175305\n",
      "FT correlation coefficent = 0.5101851304616711\n",
      "PTS correlation coefficent = 0.44179743881307093\n",
      "SOS correlation coefficent = 0.1796059783207265\n"
     ]
    }
   ],
   "source": [
    "def find_stat_correlation_to_NBA_PTS(table, headers):\n",
    "    NBA_PTS = utils.get_column(table, 10)\n",
    "    for i in range(1, len(headers)-1):\n",
    "        cur_column = utils.get_column(table, i)\n",
    "        vals = np.corrcoef(cur_column, NBA_PTS)\n",
    "        r = str(vals[0][-1])\n",
    "        print (headers[i] + \" correlation coefficent = \" + r)\n",
    "\n",
    "find_stat_correlation_to_NBA_PTS(table, headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
